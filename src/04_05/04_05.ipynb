{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62b685c1-fe44-4f01-b9e3-5808cf10752f",
   "metadata": {},
   "source": [
    "# Chat With Your Data\n",
    "\n",
    "## Solution: Chat With Your Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bed94b7-d5da-4c5b-a812-25ecbb1601a6",
   "metadata": {},
   "source": [
    "# Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603889ff-e355-4c9e-929a-45e8150aa0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759ae117-0aa2-4c09-b5bd-7ce1e106ada2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd511c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca531938",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1839e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c527ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9fcee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchainhub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef23fe7-5c16-4f30-97e4-b679c75e716d",
   "metadata": {},
   "source": [
    "## Load OpenAI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77f69144-98d1-46a1-94be-8eea00065278",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "OPENAI_API_KEY=os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafecdae-eaf9-471f-b69d-9b1c3ac0b9d2",
   "metadata": {},
   "source": [
    "## Load vector database from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0788aef1-0fe8-4205-ba3d-741bb5cf392a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "\n",
    "db = FAISS.load_local(\"../faiss_index\", \n",
    "                      OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY, model=\"text-embedding-3-small\"), \n",
    "                      allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b7e3f2-eaba-4fa1-aced-d79431959cd9",
   "metadata": {},
   "source": [
    "## Configure retriever\n",
    "### Use the similarity search capabilities of a vector store to facilitate retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ec80ca7-918a-4898-b64d-4cee56d8141a",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3536c8-60fc-40c1-8265-2249a839db08",
   "metadata": {},
   "source": [
    "## Configure LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72e8727d-0efe-495d-b896-fcb3ca9d23ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "#initialize the LLM we'll use - OpenAI GPT 3.5 Turbo\n",
    "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc0fd64-aa2e-46fe-a2c6-a0b8ca109d76",
   "metadata": {},
   "source": [
    "## Define prompt with conversation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "732ea316-19cb-435f-b822-fb0647925980",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "system_prompt = \"\"\"Given the chat history and a recent user question \\\n",
    "generate a new standalone question \\\n",
    "that can be understood without the chat history. Do NOT answer the question, \\\n",
    "just reformulate it if needed or otherwise return it as is.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "retriever_with_history = create_history_aware_retriever(\n",
    "    llm, retriever, prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05940ef-89cd-4cc5-86e3-9a27f00f94a9",
   "metadata": {},
   "source": [
    "## Perform question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c79f88f-5924-4f52-ab0e-3825e16b2be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "qa_system_prompt = \"\"\"You are an assistant for question-answering tasks. \\\n",
    "Use the following pieces of retrieved context to answer the question. \\\n",
    "If you don't know the answer, just say that you don't know. \\\n",
    "Use three sentences maximum and keep the answer concise.\\\n",
    "\n",
    "{context}\"\"\"\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(retriever_with_history, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b0088c4-b593-404e-a9d5-36649862efe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aetherfloris Ventus is a celestial plant with petals lighter than air, appearing to float freely, nurtured by the winds and clouds. It challenges our understanding of the natural world with its delicate beauty, nearly invisible stem, and spectral display. In alchemy, its essence is considered a treasure that bestows lightness upon those who partake, encouraging thoughts to soar and dreams to take flight.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "question = \"What is Aetherfloris Ventus?\"\n",
    "\n",
    "ai_msg_1 = rag_chain.invoke({\"input\": question, \"chat_history\": chat_history})\n",
    "\n",
    "chat_history.extend([HumanMessage(content=question), ai_msg_1[\"answer\"]])\n",
    "\n",
    "print(ai_msg_1[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b75d4d60-4b6b-49c6-a876-0a98bb2fbf5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A single drop of Aetherfloris Ventus can lift the spirits, freeing the mind from earthly burdens and encouraging thoughts to soar. It induces a sense of lightness in both body and mind, allowing dreams to take flight and inspiring a feeling of weightlessness. The true nature of Aetherfloris Ventus remains elusive even to dedicated seekers, representing the mysteries of the natural world waiting to be discovered.\n"
     ]
    }
   ],
   "source": [
    "second_question = \"What does a single drop of it do?\"\n",
    "\n",
    "ai_msg_2 = rag_chain.invoke({\"input\": second_question, \"chat_history\": chat_history})\n",
    "print(ai_msg_2[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67bfb493-0c2c-454d-8328-b83aed28406c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noctis Umbraherba is a dark plant thriving in the absence of light, with leaves darker than night that absorb shadows and blooming only under darkness. In contrast, Aetherfloris Ventus is a celestial plant with petals lighter than air, appearing to float freely, nurtured by the winds and clouds. While Noctis Umbraherba is shrouded in mystery and linked to the secrets of the night, Aetherfloris Ventus challenges understanding with its ethereal beauty and alchemical significance.\n"
     ]
    }
   ],
   "source": [
    "third_question = \"How does it compare to Noctis Umbraherba?\"\n",
    "ai_msg_3 = rag_chain.invoke({\"input\": third_question, \"chat_history\": chat_history})\n",
    "print(ai_msg_3[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2b60c6b-57bc-44da-9706-0060095635e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, the Biological section of the Voynich Manuscript is significant as it offers a unique blend of fantastical biology and precise anatomical detail, providing insights into ancient medical knowledge and alchemical practices. The detailed anatomical diagrams of mythical beings within this section may have served as a practical guide for medicinal and alchemical purposes, showcasing the interplay between science, magic, and art in historical contexts. The annotations accompanying these diagrams hint at the potential medicinal and pharmacological applications of the depicted organs, adding to the section's complexity and cultural significance.\n"
     ]
    }
   ],
   "source": [
    "fourth_question = \"Do you think the Biological section of the Voynich Manuscript is important?\"\n",
    "ai_msg_4 = rag_chain.invoke({\"input\": fourth_question, \"chat_history\": chat_history})\n",
    "print(ai_msg_4[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
